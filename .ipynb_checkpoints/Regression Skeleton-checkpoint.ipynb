{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find out mape\n",
    "def mape(y_actual, y_predicted):\n",
    "    s = 0\n",
    "    count = 0\n",
    "    for i in range(0,len(y_actual)):\n",
    "        if y_actual[i] != 0:\n",
    "            s = s + abs(y_actual[i] - y_predicted[i])/y_actual[i]\n",
    "            count = count + 1\n",
    "    s = s / count\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_LR = LR.predict(X_train)\n",
    "y_pred_test_LR = LR.predict(X_test)\n",
    "\n",
    "print(\"R squared Score on Train data is {:.3f}\".format(r2_score(y_train, y_pred_train_LR)))\n",
    "print(\"R squared Score on Test data is {:.3f}\".format(r2_score(y_test, y_pred_test_LR)))\n",
    "\n",
    "LR_mape = mape(y_test, y_pred_test_LR)\n",
    "LR_mae = mean_absolute_error(y_test, y_pred_test_LR)\n",
    "LR_mse = mean_squared_error(y_test, y_pred_test_LR)\n",
    "LR_rmse = LR_mse ** 0.5\n",
    "LR_metrics = [LR_mape, LR_mae, LR_mse, LR_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "table = []\n",
    "\n",
    "for i in range(2,20):\n",
    "    DR = DecisionTreeRegressor(criterion = \"mse\", max_depth = i, random_state=12)\n",
    "    DR.fit(X_train, y_train)\n",
    "    table.append([i,mape(y_test, DR.predict(X_test))])\n",
    "    \n",
    "d = pd.DataFrame(table, columns = ['max_depth','mape'])\n",
    "\n",
    "depth = int(d[d.mape == d.mape.min()]['max_depth'])\n",
    "\n",
    "DR = DecisionTreeRegressor(criterion = 'mse', max_depth = depth, random_state = 12).fit(X_train, y_train)\n",
    "y_pred_DT = DR.predict(X_test)\n",
    "DT_mape = mape(y_test, y_pred_DT)\n",
    "DT_mae = mean_absolute_error(y_test, y_pred_DT)\n",
    "DT_mse = mean_squared_error(y_test, y_pred_DT)\n",
    "DT_rmse = DT_mse ** 0.5\n",
    "DT_metrics = [DT_mape, DT_mae, DT_mse, DT_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "XGB_Perf = []\n",
    "for i in range(2,20):\n",
    "    gbr1 = GradientBoostingRegressor(n_estimators = i, random_state = 123)\n",
    "    gbr1.fit(X_train, y_train)\n",
    "    gbmape = mape(y_test, gbr1.predict(X_test))\n",
    "    XGB_Perf.append([i, gbmape])\n",
    "    \n",
    "x = pd.DataFrame(XGB_Perf, columns = ['n_estimators', 'MAPE'])\n",
    "x.head()\n",
    "\n",
    "best_estimators = int(x[x.MAPE == x.MAPE.min()]['n_estimators'])\n",
    "gbr1 = GradientBoostingRegressor(n_estimators = best_estimators, random_state = 123).fit(X_train, y_train)\n",
    "y_pred_XGB = gbr1.predict(X_test)\n",
    "XGB_mape = mape(y_test, y_pred_XGB)\n",
    "XGB_mae = mean_absolute_error(y_test, y_pred_XGB)\n",
    "XGB_mse = mean_squared_error(y_test, y_pred_XGB)\n",
    "XGB_rmse = XGB_mse ** 0.5\n",
    "XGB_metrics = [XGB_mape, XGB_mae, XGB_mse, XGB_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(n_estimators = 25, criterion = 'mse', max_depth = 30)\n",
    "RFR.fit(X_train, y_train)\n",
    "\n",
    "y_pred_RFR = RFR.predict(X_test)\n",
    "RFR_mape = mape(y_test, y_pred_RFR)\n",
    "RFR_mae = mean_absolute_error(y_test, y_pred_RFR)\n",
    "RFR_mse = mean_squared_error(y_test, y_pred_RFR)\n",
    "RFR_rmse = RFR_mse ** 0.5\n",
    "RFR_metrics = [RFR_mape, RFR_mae, RFR_mse, RFR_rmse]\n",
    "RFR_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search CV with Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params_grid = {\"l1_ratio\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "              \"alpha\":[0.01,0.1,1,10,20,30,100]}\n",
    "\n",
    "EN = ElasticNet(random_state = 0)\n",
    "\n",
    "RSCV = RandomizedSearchCV(estimator = EN, param_distributions=params_grid, cv = 3, n_iter = 10, refit = True, random_state=0)\n",
    "RSCV.fit(X_train, y_train)\n",
    "\n",
    "y_pred_EN = RSCV.predict(X_test)\n",
    "RSCV_mape = mape(y_test, y_pred_EN)\n",
    "RSCV_mae = mean_absolute_error(y_test, y_pred_EN)\n",
    "RSCV_mse = mean_squared_error(y_test, y_pred_EN)\n",
    "RSCV_rmse = RSCV_mse ** 0.5\n",
    "RSCV_metrics = [RSCV_mape, RSCV_mae, RSCV_mse, RSCV_rmse]\n",
    "print(RSCV.best_estimator_)\n",
    "RSCV_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DR = DecisionTreeRegressor(criterion = 'mse', max_depth = 20, random_state = 12).fit(X_train, y_train)\n",
    "\n",
    "ADBReg = AdaBoostRegressor(base_estimator = DR, n_estimators=20, learning_rate=0.1)\n",
    "\n",
    "y_pred_ADB = RSCV.predict(X_test)\n",
    "ADB_mape = mape(y_test, y_pred_ADB)\n",
    "ADB_mae = mean_absolute_error(y_test, y_pred_ADB)\n",
    "ADB_mse = mean_squared_error(y_test, y_pred_ADB)\n",
    "ADB_rmse = ADB_mse ** 0.5\n",
    "ADB_metrics = [ADB_mape, ADB_mae, ADB_mse, ADB_rmse]\n",
    "ADB_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor(criterion = 'mse', max_depth = 13, random_state = 12)\n",
    "model3 = RandomForestRegressor(n_estimators=100)\n",
    "model4 = ADBReg = AdaBoostRegressor(base_estimator = DR, n_estimators=20, learning_rate=0.1)\n",
    "\n",
    "SR = StackingRegressor(regressors=[model1, model2, model3, model4], meta_regressor= model1)\n",
    "SR.fit(X_train, y_train)\n",
    "\n",
    "y_pred_Stack = SR.predict(X_test)\n",
    "\n",
    "Stack_mape = mape(y_test, y_pred_Stack)\n",
    "Stack_mae = mean_absolute_error(y_test, y_pred_Stack)\n",
    "Stack_mse = mean_squared_error(y_test, y_pred_Stack)\n",
    "Stack_rmse = Stack_mse ** 0.5\n",
    "Stack_metrics = [Stack_mape, Stack_mae, Stack_mse, Stack_rmse]\n",
    "Stack_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
